{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45be2379-fe03-4105-9231-379c564fc89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from hmmlearn import hmm\n",
    "import joblib \n",
    "import os\n",
    "from typing import Dict, List, Tuple, Any\n",
    "\n",
    "# HMMの隠れ状態（感情ラベル）：4つ\n",
    "EMOTIONAL_STATES = [\n",
    "    '感覚運動的興奮', \n",
    "    '難解・頭脳型', \n",
    "    '和みと癒し', \n",
    "    '設定状況の魅力' \n",
    "]\n",
    "N_STATES = len(EMOTIONAL_STATES)\n",
    "N_FEATURES = 5 # 特徴量の次元数\n",
    "MODEL_FILENAME = 'hmm_emotion_model_4states.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6044e8e5-57bd-40bf-bb30-051a1939850e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2.1 キーログからの特徴量抽出関数 ---\n",
    "def extract_features_from_keylog(log_data: pd.DataFrame, time_window_sec: float = 30.0) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    キーログデータ（CSV読み込み後）を時間窓で区切り、HMMの観測特徴量を抽出します。\n",
    "    5つの特徴量: [持続時間平均, 遅延時間平均, APM, 持続時間分散, 停止時間割合]\n",
    "    \"\"\"\n",
    "    \n",
    "    # 列名の統一と型変換\n",
    "    log_data.rename(columns={'経過時間(s) (セッション開始からの時間)': 'elapsed_time',\n",
    "                             '持続時間(s)': 'duration',\n",
    "                             '遅延時間(s)': 'delay'}, inplace=True)\n",
    "    \n",
    "    try:\n",
    "        log_data['elapsed_time'] = log_data['elapsed_time'].astype(float)\n",
    "        log_data['duration'] = log_data['duration'].astype(float)\n",
    "        log_data['delay'] = log_data['delay'].astype(float)\n",
    "    except Exception as e:\n",
    "        print(f\"データの型変換エラー: {e}\")\n",
    "        return np.array([]), np.array([])\n",
    "    \n",
    "    max_time = log_data['elapsed_time'].max()\n",
    "    segments = []\n",
    "    \n",
    "    start_time = 0.0\n",
    "    while start_time < max_time + time_window_sec:\n",
    "        end_time = start_time + time_window_sec\n",
    "        window_data = log_data[(log_data['elapsed_time'] >= start_time) & (log_data['elapsed_time'] < end_time)]\n",
    "        \n",
    "        if len(window_data) == 0:\n",
    "            feature_vector = [0.0, time_window_sec, 0.0, 0.0, 1.0] \n",
    "        else:\n",
    "            duration_mean = window_data['duration'].mean()\n",
    "            delay_mean = window_data['delay'].mean()\n",
    "            apm = len(window_data) / time_window_sec * 60\n",
    "            duration_var = window_data['duration'].var()\n",
    "            if np.isnan(duration_var): duration_var = 0.0\n",
    "            total_active_duration = window_data['duration'].sum()\n",
    "            stop_time_ratio = (time_window_sec - total_active_duration) / time_window_sec\n",
    "            stop_time_ratio = max(0.0, min(1.0, stop_time_ratio))\n",
    "            \n",
    "            feature_vector = [duration_mean, delay_mean, apm, duration_var, stop_time_ratio]\n",
    "            \n",
    "        segments.append(feature_vector)\n",
    "        start_time = end_time\n",
    "\n",
    "    X = np.array(segments)\n",
    "    lengths = np.array([len(X)])\n",
    "    \n",
    "    return X, lengths\n",
    "\n",
    "# --- 2.2 HMM学習/分類クラス ---\n",
    "class HMMGameEmotionClassifier:\n",
    "    \"\"\"キーログ特徴量から4つのゲーム感情ラベルを推定するHMM分類器\"\"\"\n",
    "    \n",
    "    def __init__(self, n_components: int = N_STATES, n_features: int = N_FEATURES):\n",
    "        self.model = hmm.GaussianHMM(\n",
    "            n_components=n_components, \n",
    "            covariance_type=\"diag\", \n",
    "            n_iter=100,\n",
    "            init_params=\"stmc\",\n",
    "            transmat_prior=1.0,\n",
    "            startprob_prior=1.0\n",
    "        )\n",
    "        self.state_names = EMOTIONAL_STATES\n",
    "\n",
    "    def train(self, X: np.ndarray, lengths: np.ndarray):\n",
    "        \"\"\"HMMモデルを訓練します。\"\"\"\n",
    "        print(f\"HMMモデルを訓練中... (隠れ状態数: {self.model.n_components})\")\n",
    "        if X.shape[1] != N_FEATURES:\n",
    "            print(f\"❌ エラー: 訓練データの特徴量次元が一致しません ({X.shape[1]} != {N_FEATURES})\")\n",
    "            return\n",
    "        try:\n",
    "            self.model.fit(X, lengths)\n",
    "            print(\"✅ HMMモデルの訓練が完了しました。\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ HMMの訓練中にエラーが発生しました: {e}\")\n",
    "\n",
    "    def predict_emotion_sequence(self, X: np.ndarray) -> List[str]:\n",
    "        \"\"\"観測データから、最も適合する感情ラベルの時系列を推定します。\"\"\"\n",
    "        if self.model.n_iter == 0:\n",
    "             print(\"警告: モデルが訓練されていません。\")\n",
    "             return []\n",
    "        logprob, state_sequence = self.model.decode(X, algorithm=\"viterbi\")\n",
    "        return [self.state_names[state] for state in state_sequence]\n",
    "\n",
    "    def save_model(self, filename: str = MODEL_FILENAME):\n",
    "        \"\"\"訓練済みモデルを保存します。\"\"\"\n",
    "        joblib.dump(self.model, filename)\n",
    "        joblib.dump(self.state_names, filename.replace('.pkl', '_states.pkl'))\n",
    "        print(f\"✅ モデルと状態名を '{filename}' に保存しました。\")\n",
    "\n",
    "    @classmethod\n",
    "    def load_model(cls, filename: str = MODEL_FILENAME):\n",
    "        \"\"\"保存されたモデルを読み込みます。\"\"\"\n",
    "        if not os.path.exists(filename):\n",
    "            raise FileNotFoundError(f\"モデルファイル '{filename}' が見つかりません。\")\n",
    "        instance = cls()\n",
    "        instance.model = joblib.load(filename)\n",
    "        instance.state_names = joblib.load(filename.replace('.pkl', '_states.pkl'))\n",
    "        print(f\"✅ モデルを '{filename}' から正常に読み込みました。\")\n",
    "        return instance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412e09b4",
   "metadata": {},
   "source": [
    "### ダミーデータバージョン"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255ad9b6",
   "metadata": {},
   "source": [
    "### 訓練データバージョン"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a30d9c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting a model with 55 free scalar parameters with only 30 data points will result in a degenerate solution.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 訓練データ準備中: kiyotaANOTEr.csvを読み込み ---\n",
      "✅ データ結合完了。総セグメント数: 6、総セッション数: 6\n",
      "HMMモデルを訓練中... (隠れ状態数: 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some rows of transmat_ have zero sum because no transition from the state was ever observed.\n",
      "Model is not converging.  Current: 14.836418718881328 is not greater than 17.02512101363289. Delta is -2.188702294751563\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ HMMモデルの訓練が完了しました。\n",
      "✅ モデルと状態名を 'kiyota.pkl' に保存しました。\n",
      "\n",
      "✅ モデルの訓練と保存が完了しました。推定の準備ができました。\n"
     ]
    }
   ],
   "source": [
    "# --- 3.1: 訓練データの準備バージョン ---\n",
    "\n",
    "# ★★★ 訓練データCSVのパスを指定してください ★★★\n",
    "HMM_TRAIN_DATA_PATH = 'kiyotaANOTEr.csv' \n",
    "\n",
    "# ★★★ アノテーションとセッションIDの列名を指定してください ★★★\n",
    "EMOTION_COL = 'True_Emotion' \n",
    "SESSION_ID_COL = 'Session_ID' \n",
    "\n",
    "print(f\"--- 訓練データ準備中: {HMM_TRAIN_DATA_PATH}を読み込み ---\")\n",
    "\n",
    "try:\n",
    "    df_train = pd.read_csv(HMM_TRAIN_DATA_PATH)\n",
    "except FileNotFoundError:\n",
    "    print(f\"❌ エラー: 訓練データファイル '{HMM_TRAIN_DATA_PATH}' が見つかりません。\")\n",
    "    # 実行を中断\n",
    "    # exit() \n",
    "\n",
    "    \n",
    "    \n",
    "# 特徴量となる列名を定義\n",
    "# 感情ラベル列とセッションID列以外の全ての列を特徴量と見なします。\n",
    "feature_columns = [col for col in df_train.columns \n",
    "                   if col not in [EMOTION_COL, SESSION_ID_COL]]\n",
    "\n",
    "# 感情ラベルの順序をHMMの状態順に合わせるためのマッピング\n",
    "state_to_index = {name: i for i, name in enumerate(EMOTIONAL_STATES)}\n",
    "\n",
    "# --- データの前処理と結合 ---\n",
    "\n",
    "# セッションIDでデータをグループ化\n",
    "grouped = df_train.groupby(SESSION_ID_COL)\n",
    "\n",
    "X_train_list = []\n",
    "lengths_train_list = []\n",
    "\n",
    "for session_id, session_df in grouped:\n",
    "    # 特徴量データ (X) を抽出\n",
    "    X_session = session_df[feature_columns].values\n",
    "    \n",
    "    # 感情ラベル (教師信号) を抽出 (今回は教師信号はHMMの構造学習には不要だが、検証用に重要)\n",
    "    # y_session = session_df[EMOTION_COL].map(state_to_index).values \n",
    "\n",
    "    X_train_list.append(X_session)\n",
    "    lengths_train_list.append(len(X_session))\n",
    "\n",
    "X_train = np.vstack(X_train_list)\n",
    "lengths_train = np.array(lengths_train_list)\n",
    "\n",
    "print(f\"✅ データ結合完了。総セグメント数: {len(X_train)}、総セッション数: {len(lengths_train)}\")\n",
    "\n",
    "# --- 3.2: モデルの訓練と保存 ---\n",
    "\n",
    "if X_train.size == 0:\n",
    "    print(\"エラー: 訓練データが空です。処理を中止します。\")\n",
    "else:\n",
    "    # 1. モデルの訓練と保存\n",
    "    classifier = HMMGameEmotionClassifier()\n",
    "    classifier.train(X_train, lengths_train)\n",
    "    \n",
    "    MODEL_FILENAME = 'kiyota.pkl'\n",
    "    classifier.save_model(MODEL_FILENAME)\n",
    "    \n",
    "    print(f\"\\n✅ モデルの訓練と保存が完了しました。推定の準備ができました。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a209cb58-7385-47fe-9f51-14e102218880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ モデルを 'kiyota.pkl' から正常に読み込みました。\n",
      "\n",
      "--- 推定開始: ファイル '/Users/sakumasin/Documents/GitHub/kenkyu/mizuki2025/keylogmizuki/sakuma.csv' の特徴量を抽出中 ---\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "transmat_ rows must sum to 1 (got row sums of [0. 0. 0. 0.])",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 33\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m推定をスキップ: テストデータの特徴量抽出に失敗しました。\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;66;03m# --- 4.4: 感情の推定と結果表示 ---\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m     estimated_emotions \u001b[38;5;241m=\u001b[39m \u001b[43mloaded_classifier\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_emotion_sequence\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m--- 最終的な感情推定結果（30秒間隔） ---\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, emotion \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(estimated_emotions):\n",
      "Cell \u001b[0;32mIn[2], line 83\u001b[0m, in \u001b[0;36mHMMGameEmotionClassifier.predict_emotion_sequence\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     81\u001b[0m      \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m警告: モデルが訓練されていません。\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     82\u001b[0m      \u001b[38;5;28;01mreturn\u001b[39;00m []\n\u001b[0;32m---> 83\u001b[0m logprob, state_sequence \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malgorithm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mviterbi\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate_names[state] \u001b[38;5;28;01mfor\u001b[39;00m state \u001b[38;5;129;01min\u001b[39;00m state_sequence]\n",
      "File \u001b[0;32m/opt/anaconda3/envs/keyst/lib/python3.8/site-packages/hmmlearn/base.py:336\u001b[0m, in \u001b[0;36m_AbstractHMM.decode\u001b[0;34m(self, X, lengths, algorithm)\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;124;03mFind most likely state sequence corresponding to ``X``.\u001b[39;00m\n\u001b[1;32m    303\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;124;03mscore : Compute the log probability under the model.\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    335\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstartprob_\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 336\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m algorithm \u001b[38;5;241m=\u001b[39m algorithm \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malgorithm\n\u001b[1;32m    339\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m algorithm \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m DECODER_ALGORITHMS:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/keyst/lib/python3.8/site-packages/hmmlearn/hmm.py:325\u001b[0m, in \u001b[0;36mGaussianHMM._check\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    324\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 325\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    327\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmeans_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmeans_)\n\u001b[1;32m    328\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmeans_\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m/opt/anaconda3/envs/keyst/lib/python3.8/site-packages/hmmlearn/base.py:977\u001b[0m, in \u001b[0;36mBaseHMM._check\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    974\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransmat_\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m!=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_components, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_components):\n\u001b[1;32m    975\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    976\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransmat_ must have shape (n_components, n_components)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 977\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_sum_1\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtransmat_\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/keyst/lib/python3.8/site-packages/hmmlearn/base.py:951\u001b[0m, in \u001b[0;36mBaseHMM._check_sum_1\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    949\u001b[0m s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, name)\u001b[38;5;241m.\u001b[39msum(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    950\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39mallclose(s, \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m--> 951\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    952\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must sum to 1 (got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00ms\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    953\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m s\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    954\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m rows must sum to 1 (got row sums of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00ms\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    955\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m s\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    956\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected 1D or 2D array\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: transmat_ rows must sum to 1 (got row sums of [0. 0. 0. 0.])"
     ]
    }
   ],
   "source": [
    "# --- 4.1: 推定データの指定 ---\n",
    "# ★★★ ここを推定したいキーログCSVのパスに置き換えてください ★★★\n",
    "TEST_CSV_PATH = '/Users/sakumasin/Documents/GitHub/kenkyu/mizuki2025/keylogmizuki/sakuma.csv' \n",
    "\n",
    "# 【注意】TEST_CSV_PATHのデータは、訓練データと同じ列名(持続時間(s)など)が必要です。\n",
    "\n",
    "# --- 4.2: モデルの読み込み ---\n",
    "try:\n",
    "    loaded_classifier = HMMGameEmotionClassifier.load_model(MODEL_FILENAME)\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"❌ エラー: モデルファイルが見つかりません。ブロック3を実行してモデルを訓練・保存してください。\")\n",
    "    # ここで実行を中断\n",
    "    # raise e\n",
    "\n",
    "# --- 4.3: 特徴量の抽出 ---\n",
    "print(f\"\\n--- 推定開始: ファイル '{TEST_CSV_PATH}' の特徴量を抽出中 ---\")\n",
    "\n",
    "try:\n",
    "    df_test = pd.read_csv(TEST_CSV_PATH)\n",
    "except FileNotFoundError:\n",
    "    print(f\"❌ エラー: ファイル '{TEST_CSV_PATH}' が見つかりません。\")\n",
    "    df_test = pd.DataFrame()\n",
    "\n",
    "if not df_test.empty:\n",
    "    X_test, _ = extract_features_from_keylog(df_test, time_window_sec=30.0)\n",
    "else:\n",
    "    X_test = np.array([])\n",
    "\n",
    "if X_test.size == 0:\n",
    "    print(\"推定をスキップ: テストデータの特徴量抽出に失敗しました。\")\n",
    "else:\n",
    "    # --- 4.4: 感情の推定と結果表示 ---\n",
    "    estimated_emotions = loaded_classifier.predict_emotion_sequence(X_test)\n",
    "    \n",
    "    print(\"\\n--- 最終的な感情推定結果（30秒間隔） ---\")\n",
    "    for i, emotion in enumerate(estimated_emotions):\n",
    "        time_start = i * 30\n",
    "        time_end = (i + 1) * 30\n",
    "        print(f\"時間窓 {time_start}-{time_end}秒: {emotion}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
